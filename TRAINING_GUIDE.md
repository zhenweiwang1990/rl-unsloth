# GRPO è®­ç»ƒæŒ‡å—

## ğŸš€ ç»Ÿä¸€è®­ç»ƒè„šæœ¬

æ‰€æœ‰è®­ç»ƒåŠŸèƒ½å·²åˆå¹¶åˆ°å•ä¸ªæ–‡ä»¶ï¼š`train_grpo.py`

## ğŸ“‹ è®­ç»ƒæ¨¡å¼

### 1. Masked æ¨¡å¼ï¼ˆæ¨èï¼‰â­

å®Œæ•´çš„ token çº§åˆ«æ©ç å®ç°ï¼Œæ¶æ„æœ€æ­£ç¡®ã€‚

```bash
# é»˜è®¤æ¨¡å¼
python train_grpo.py --mode masked

# æˆ–è€…ç®€å†™
python train_grpo.py
```

**ç‰¹ç‚¹**ï¼š
- âœ… çœŸå® agent rollouts
- âœ… Token çº§åˆ«æ©ç 
- âœ… åªè®­ç»ƒæ¨¡å‹ç”Ÿæˆçš„ tokens
- âœ… Tool results ä¸å‚ä¸è®­ç»ƒ
- âœ… å®Œæ•´çš„ GRPO ç®—æ³•
- âš ï¸  è®­ç»ƒè¾ƒæ…¢ï¼ˆä½†æ­£ç¡®ï¼‰

**é€‚åˆ**ï¼šæ­£å¼è®­ç»ƒã€è¿½æ±‚æœ€ä½³æ€§èƒ½

---

### 2. Rollout æ¨¡å¼

ä½¿ç”¨çœŸå® rolloutsï¼Œä½†æ²¡æœ‰å®Œæ•´çš„ token æ©ç ã€‚

```bash
python train_grpo.py --mode rollout
```

**ç‰¹ç‚¹**ï¼š
- âœ… çœŸå® agent rollouts
- âœ… åŸºäºçœŸå®æ€§èƒ½çš„ reward
- âŒ æ²¡æœ‰ token æ©ç ï¼ˆä¼šè®­ç»ƒ tool resultsï¼‰
- âš ï¸  æ¶æ„ä¸å®Œå…¨æ­£ç¡®

**é€‚åˆ**ï¼šå¿«é€ŸéªŒè¯ã€ä¸­ç­‰è§„æ¨¡æµ‹è¯•

---

### 3. Simple æ¨¡å¼

ä½¿ç”¨ TRL å¿«é€Ÿè®­ç»ƒï¼ŒåŸºäºå¯å‘å¼ rewardã€‚

```bash
python train_grpo.py --mode simple
```

**ç‰¹ç‚¹**ï¼š
- âŒ é™æ€æ•°æ®ï¼ˆæ²¡æœ‰çœŸå® rolloutsï¼‰
- âŒ å¯å‘å¼ rewardï¼ˆä¸åŸºäºçœŸå®æ€§èƒ½ï¼‰
- âŒ æ²¡æœ‰ token æ©ç 
- âœ… è®­ç»ƒå¿«é€Ÿ

**é€‚åˆ**ï¼šå¿«é€ŸåŸå‹ã€åŠŸèƒ½æµ‹è¯•

---

## âš™ï¸ é…ç½®å‚æ•°

### åŸºæœ¬é…ç½®

```bash
# æ•°æ®é›†å¤§å°
export TRAIN_DATASET_SIZE=50
export EVAL_DATASET_SIZE=20

# è®­ç»ƒå‚æ•°
export MAX_STEPS=200
export LEARNING_RATE=1e-5
export PER_DEVICE_TRAIN_BATCH_SIZE=2

# GRPO å‚æ•°
export NUM_GENERATIONS=4
export BETA=0.01

# Agent å‚æ•°
export MAX_TURNS=4
export MAX_TOKENS=2048

# è¾“å‡ºç›®å½•ï¼ˆä¼šæ ¹æ®æ¨¡å¼è‡ªåŠ¨è°ƒæ•´ï¼‰
export OUTPUT_DIR=outputs/grpo

# è¿è¡Œ
python train_grpo.py --mode masked
```

### æ¨èé…ç½®

#### å¿«é€Ÿæµ‹è¯•
```bash
export TRAIN_DATASET_SIZE=10
export EVAL_DATASET_SIZE=5
export MAX_STEPS=20
export NUM_GENERATIONS=2
python train_grpo.py --mode masked
```

#### æ­£å¼è®­ç»ƒ
```bash
export TRAIN_DATASET_SIZE=100
export EVAL_DATASET_SIZE=30
export MAX_STEPS=500
export NUM_GENERATIONS=4
export LEARNING_RATE=1e-5
export BETA=0.01
python train_grpo.py --mode masked
```

---

## ğŸ“Š è®­ç»ƒè¾“å‡º

### Masked æ¨¡å¼æ—¥å¿—

```
============================================================
GRPO Training - Mode: MASKED
============================================================
âœ… Full implementation with token-level masking (RECOMMENDED)
============================================================
AgentGRPOTrainer initialized
============================================================
Train queries: 50
Eval queries: 20
Rollouts per query: 4
Target accuracy: 95.0%
============================================================

Step 1/200 | Loss: 0.5234 | Policy: 0.5123 | KL: 0.0111 | 
Reward: 0.456 | Acc: 25.0% | 
Trainable tokens: 1234/5678 (21.7%)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Evaluation at step 50
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Evaluating on 20 queries...
ğŸ“Š Eval reward: 0.723
ğŸ“Š Eval accuracy: 45.00%
âœ¨ New best accuracy: 45.00%
ğŸ’¾ Model saved to: outputs/grpo_masked/best_model
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

### å…³é”®æŒ‡æ ‡

- **Trainable tokens æ¯”ä¾‹**ï¼š20-30% æ­£å¸¸ï¼ˆmasked æ¨¡å¼ï¼‰
- **Loss**ï¼šåº”è¯¥é€æ¸ä¸‹é™
- **Reward**ï¼šåº”è¯¥é€æ¸ä¸Šå‡ï¼ˆ0.2 â†’ 1.5ï¼‰
- **Accuracy**ï¼šåº”è¯¥é€æ¸ä¸Šå‡ï¼ˆ10% â†’ 95%ï¼‰

---

## ğŸ¯ æ¨¡å¼é€‰æ‹©å»ºè®®

| éœ€æ±‚ | æ¨èæ¨¡å¼ | åŸå›  |
|-----|---------|------|
| æ­£å¼è®­ç»ƒ | masked | æ¶æ„æ­£ç¡®ï¼Œæ€§èƒ½æœ€ä½³ |
| å¿«é€ŸéªŒè¯ | rollout | çœŸå® rolloutï¼Œé€Ÿåº¦é€‚ä¸­ |
| åŠŸèƒ½æµ‹è¯• | simple | æœ€å¿«é€Ÿï¼Œé€‚åˆè°ƒè¯• |
| è¿½æ±‚æ€§èƒ½ | masked | å”¯ä¸€æ­£ç¡®çš„å®ç° |
| èµ„æºæœ‰é™ | simple | æœ€çœæ—¶é—´å’Œèµ„æº |

---

## ğŸ“ è¾“å‡ºæ–‡ä»¶

è®­ç»ƒå®Œæˆåä¼šç”Ÿæˆï¼š

```
outputs/grpo_[mode]/
â”œâ”€â”€ best_model/              # æœ€ä½³æ¨¡å‹ï¼ˆå‡†ç¡®ç‡æœ€é«˜ï¼‰
â”‚   â”œâ”€â”€ adapter_model.safetensors
â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â”œâ”€â”€ metadata.json        # åŒ…å«å‡†ç¡®ç‡ç­‰ä¿¡æ¯
â”‚   â””â”€â”€ ...
â”œâ”€â”€ final/                   # æœ€ç»ˆæ¨¡å‹
â”‚   â””â”€â”€ ...
â””â”€â”€ checkpoint-*/            # ä¸­é—´æ£€æŸ¥ç‚¹
    â””â”€â”€ ...
```

### ä½¿ç”¨æœ€ä½³æ¨¡å‹

```python
from unsloth import FastLanguageModel
from email_agent.agent import EmailAgent

# åŠ è½½æœ€ä½³æ¨¡å‹
model, tokenizer = FastLanguageModel.from_pretrained(
    "outputs/grpo_masked/best_model"
)

# åˆ›å»º agent
agent = EmailAgent(model, tokenizer, policy_config)
```

---

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜ï¼šå†…å­˜ä¸è¶³

```bash
# å‡å°æ‰¹æ¬¡å’Œ rollouts
export PER_DEVICE_TRAIN_BATCH_SIZE=1
export NUM_GENERATIONS=2
export MAX_TOKENS=1024
```

### é—®é¢˜ï¼šè®­ç»ƒå¤ªæ…¢

```bash
# ä½¿ç”¨ simple æˆ– rollout æ¨¡å¼
python train_grpo.py --mode rollout

# æˆ–å‡å°‘æ•°æ®é›†
export TRAIN_DATASET_SIZE=20
export NUM_GENERATIONS=2
```

### é—®é¢˜ï¼šå‡†ç¡®ç‡ä¸æå‡

1. æ£€æŸ¥ trainable tokens æ¯”ä¾‹ï¼ˆmasked æ¨¡å¼åº”è¯¥ 20-30%ï¼‰
2. æ£€æŸ¥ reward æ˜¯å¦å¢é•¿
3. å°è¯•è°ƒæ•´å­¦ä¹ ç‡
4. éªŒè¯æ•°æ®é›†è´¨é‡

---

## ğŸ†š æ¨¡å¼å¯¹æ¯”

| ç‰¹æ€§ | Simple | Rollout | Masked |
|-----|--------|---------|--------|
| çœŸå® Rollout | âŒ | âœ… | âœ… |
| Token æ©ç  | âŒ | âŒ | âœ… |
| è®­ç»ƒé€Ÿåº¦ | å¿« | ä¸­ç­‰ | æ…¢ |
| æ¶æ„æ­£ç¡®æ€§ | âŒ | âš ï¸ | âœ… |
| é¢„æœŸæ€§èƒ½ | å·® | ä¸­ç­‰ | æœ€å¥½ |
| æ¨èä½¿ç”¨ | æµ‹è¯• | éªŒè¯ | ç”Ÿäº§ |

---

## ğŸ’¡ æœ€ä½³å®è·µ

### è®­ç»ƒæµç¨‹

1. **å¿«é€ŸéªŒè¯**ï¼ˆ5-10åˆ†é’Ÿï¼‰
   ```bash
   export TRAIN_DATASET_SIZE=10
   export MAX_STEPS=20
   python train_grpo.py --mode simple
   ```

2. **ä¸­ç­‰æµ‹è¯•**ï¼ˆ30-60åˆ†é’Ÿï¼‰
   ```bash
   export TRAIN_DATASET_SIZE=30
   export MAX_STEPS=100
   python train_grpo.py --mode rollout
   ```

3. **æ­£å¼è®­ç»ƒ**ï¼ˆ2-4å°æ—¶ï¼‰
   ```bash
   export TRAIN_DATASET_SIZE=100
   export MAX_STEPS=500
   python train_grpo.py --mode masked
   ```

### è¶…å‚æ•°è°ƒä¼˜

```bash
# å­¦ä¹ ç‡æ‰«æ
for lr in 1e-5 5e-6 1e-6; do
    export LEARNING_RATE=$lr
    python train_grpo.py --mode masked
done
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- `TOKEN_MASKING_GUIDE.md` - Token æ©ç è¯¦ç»†è¯´æ˜
- `MASKED_TRAINING_GUIDE.md` - Masked æ¨¡å¼å®Œæ•´æŒ‡å—
- `BEFORE_AFTER_COMPARISON.md` - æ”¹è¿›å‰åå¯¹æ¯”

---

## âœ… å¿«é€Ÿå¼€å§‹

```bash
# 1. è®¾ç½®ç¯å¢ƒå˜é‡
export TRAIN_DATASET_SIZE=50
export EVAL_DATASET_SIZE=20
export MAX_STEPS=200

# 2. è¿è¡Œè®­ç»ƒï¼ˆæ¨è masked æ¨¡å¼ï¼‰
python train_grpo.py --mode masked

# 3. æ£€æŸ¥è¾“å‡º
ls -la outputs/grpo_masked/best_model/

# 4. æŸ¥çœ‹å…ƒæ•°æ®
cat outputs/grpo_masked/best_model/metadata.json
```

---

## ğŸ‰ æ€»ç»“

- **ä¸€ä¸ªè„šæœ¬ï¼Œä¸‰ç§æ¨¡å¼**ï¼š`train_grpo.py`
- **æ¨èä½¿ç”¨**ï¼š`--mode masked`
- **å¿«é€Ÿæµ‹è¯•**ï¼š`--mode simple`
- **ä¸­ç­‰æ–¹æ¡ˆ**ï¼š`--mode rollout`

ç«‹å³å¼€å§‹ï¼š
```bash
python train_grpo.py --mode masked
```

